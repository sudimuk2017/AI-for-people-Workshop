{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kflazTyXbQP1"
   },
   "source": [
    "Install Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sv5NmGpcaplJ"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO-N2fynM53t"
   },
   "source": [
    "# Inspecting the dataset\n",
    "\n",
    "\n",
    "1.   Download the MNIST dataset\n",
    "2.   Plot some images with their labels\n",
    "3.   What kind of data is it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Tt07gRCDrqv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "downloaded_train = datasets.MNIST(root=\".\", train=True, download=True)\n",
    "downloaded_test = datasets.MNIST(root=\".\", train=False, download=True)\n",
    "\n",
    "print(downloaded_train)\n",
    "print(downloaded_test)\n",
    "\n",
    "# Inspect dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What are the min-max values? Does this tell us something about the data?\n",
    "print(f\"Min  Max \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiEEgR6JNVQY"
   },
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "\n",
    "1.   Convert grey-image values to 0-1 range\n",
    "2.   Create an additional validation set from the training set\n",
    "3.   Normalize the data by calculating mean and standard deviation from training set\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uz7arIjpGZ3C"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "downloaded_train = datasets.MNIST(root=\".\", train=True, download=True)\n",
    "downloaded_test = datasets.MNIST(root=\".\", train=False, download=True)\n",
    "\n",
    "# Convert grey-image values to float\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split training into training and validation set\n",
    "\n",
    "\n",
    "\n",
    "# Check dimensions\n",
    "print(train_data.shape, validation_data.shape, test_data.shape)\n",
    "\n",
    "# Normalize all three datasets (using mean and std from only the training set)\n",
    "# Also possible to use min-max scaling\n",
    "\n",
    "# Calc mean and std from training set data\n",
    "\n",
    "\n",
    "print(f\"mean_train: {mean_train:.5f}, std_train: {std_train:.5f}\")\n",
    "\n",
    "# Normalize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (Sanity-check) Are they normalized now? (Mean should be 0 and Standard-deviation should be 1)\n",
    "print()\n",
    "print(\"Sanity-check: Mean should be 0 and Standard-deviation should be 1\")\n",
    "print(f\"Train-data:      Mean: {torch.mean(train_data).item():.4f} Std: {torch.std(train_data).item():.4f}\")\n",
    "print(f\"Validation-data: Mean: {torch.mean(validation_data).item():.4f} Std: {torch.std(validation_data).item():.4f}\")\n",
    "print(f\"Test-data:       Mean: {torch.mean(test_data).item():.4f} Std: {torch.std(test_data).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sZcxlmuMVMX"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Creating a PyTorch Dataset requires the following functions implemented:\n",
    "\n",
    "\n",
    "*   \\_\\_init__(self, **params)\n",
    "*   \\_\\_getitem__(self, idx)\n",
    "*   \\_\\_len__(self)\n",
    "\n",
    "Then use this class to create datasets from our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufDrnpJHGeZ6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Create a dataset class that holds the data and targets\n",
    "class MyMNISTdataset(Dataset):\n",
    "    # Need to implement __init__(self, **params), __getitem__(self, idx), __len__(self)\n",
    "    def __init__(self, data, targets):\n",
    "        super(MyMNISTdataset, self)\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "\n",
    "# Create the datasets using the class\n",
    "\n",
    "\n",
    "\n",
    "print(\"Datasets created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCHhJK_yb-6h"
   },
   "source": [
    "Create dataloader with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltZ97B-YOz-4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Length train_dl: \", len(train_dl))\n",
    "print(\"Length valid_dl: \", len(valid_dl))\n",
    "print(\"Length test_dl: \", len(test_dl))\n",
    "\n",
    "# What is the length of the dataloader?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bFmUYA4CPYFW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# The cool stuff begins:\n",
    "### Creating the neural network\n",
    "\n",
    "Simple network building with nn.Sequential()\n",
    "\n",
    "For e.g. a Multilayer Perceptron\n",
    "\n",
    "<img src=\"https://i.imgur.com/DGY97pw.png\" height=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnHeSyGsPYbk"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Function to count (trainable) parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = nn.Sequential(\n",
    "                      \n",
    "                      \n",
    "\n",
    "                      \n",
    "                    )\n",
    "print(\"Parameters: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsY-7Nc3RX6h"
   },
   "source": [
    "### Or create a network class that implements:\n",
    "\n",
    "\n",
    "*   \\_\\_init__(self, *params)\n",
    "*   forward(self, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsXCHwP7RP0b"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "model = SimpleMLP()\n",
    "print(\"Parameters: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amjZ7wb1TJnI"
   },
   "source": [
    "# Building the training loop:\n",
    "\n",
    "\n",
    "1. Create model\n",
    "2. Choose optimizer\n",
    "3. Select appropriate loss function\n",
    "4. Iterate through training dataloader:\n",
    "  1. Feed data into model\n",
    "  2. Compare true vs predicted value\n",
    "  3. Backpropagate\n",
    "5. Iterate through validation dataloader:\n",
    "  1. Feed data into model\n",
    "  2. Compare true vs predicted value\n",
    "  3. Count correct predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLmc-1yWRQBu"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create the model\n",
    "\n",
    "print(\"Parameters: \", count_parameters(model))\n",
    "\n",
    "# Choose optimizer\n",
    "\n",
    "# Select loss function\n",
    "\n",
    "\n",
    "# Training epochs\n",
    "\n",
    "for i in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        # Do backpropagation\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Validate with valid_dl\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # Epoch done. Print losses\n",
    "    print(f\"Epoch: {i}, train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, Correct predictions: {correct*100:.2f}%, Time: {time.time()-start_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZCcTizedA71"
   },
   "source": [
    "### Now test the trained model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRyCbxcGcDMN"
   },
   "outputs": [],
   "source": [
    "test_correct = 0.0\n",
    "test_loss = 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dl:\n",
    "        y_pred = model(torch.flatten(data, 1))\n",
    "        # y_pred = model(data)\n",
    "        loss = nn.functional.cross_entropy(y_pred, target)\n",
    "        test_loss += loss.item()\n",
    "        # Check correct predictions\n",
    "        test_correct += torch.sum(torch.argmax(y_pred, dim=1) == target).item()\n",
    "    test_loss /= len(test_dl)\n",
    "    test_correct /= len(test_dl.dataset)\n",
    "print(f\"Test-scores: Loss: {test_loss:.4f}, Correct Predictions: {test_correct*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjP9q08ehRDH"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Here is an example CNN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2SFPfVFexky"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
    "        # 28-5+1 = 24\n",
    "        self.max1 = nn.MaxPool2d(2)\n",
    "        # 24/2 = 12\n",
    "        self.conv2 = nn.Conv2d(16, 4, kernel_size=3, padding=0)\n",
    "        # 12-3+1 = 10\n",
    "        self.max2 = nn.MaxPool2d(2)\n",
    "        # 10/2 = 5\n",
    "        self.lin = nn.Linear(5*5*4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add a dummy dimension\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.lin(torch.flatten(x, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLSMwg84dHjf"
   },
   "source": [
    "### But how do I run this on the GPU?!\n",
    "Move the model and the data to the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXNf586odZFX"
   },
   "outputs": [],
   "source": [
    "# Do I have a GPU in the first place?\n",
    "import torch\n",
    "print(\"Cuda available!\" if torch.cuda.is_available() else \"Only CPU available :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lne3mlvfdUP3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfcq0TNnj69T"
   },
   "source": [
    "# Some advanced concepts:\n",
    "\n",
    "\n",
    "Saving model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzZ-UqE3j8ZS"
   },
   "outputs": [],
   "source": [
    "# Save model parameters only (recommended)\n",
    "torch.save({\"state_dict\": model.state_dict()}, f\"saved_model.pt\")\n",
    "\n",
    "# Save whole model+parameters (requires source code and may get problematic if source code changes)\n",
    "torch.save(\"model\": model, \"state_dict\": model.state_dict(), f\"saved_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GqAyJTpmMJp"
   },
   "source": [
    "Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vhci2ezkmMvl"
   },
   "outputs": [],
   "source": [
    "# Load model parameters only (recommended)\n",
    "loaded_model_file = torch.load(\"saved_model.pt\")\n",
    "model = MySimpleMLP()\n",
    "model.load_state_dict(loaded_model_file[\"state_dict\"])\n",
    "\n",
    "# Load whole model+parameters\n",
    "loaded_model_file = torch.load(\"saved_model.pt\")\n",
    "model = loaded_model_file[\"model\"]\n",
    "model.load_state_dict(loaded_model_file[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbPhdmP1mX8Q"
   },
   "source": [
    "Earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Esfd6Pr4mYBp"
   },
   "outputs": [],
   "source": [
    "if valid_loss < best_val_loss:\n",
    "    os.makedirs(\"models/checkpoints\", exist_ok=True)\n",
    "    # Save best model\n",
    "    torch.save({\"state_dict\": model.state_dict()}, f\"best_val_loss_model.pt\")\n",
    "    best_val_loss = valid_loss\n",
    "    earlystopping_counter = 0\n",
    "# Stop training if validation loss has not increased for `earlystopping` epochs\n",
    "else:\n",
    "    if earlystopping is not None:\n",
    "        earlystopping_counter += 1\n",
    "        if earlystopping_counter >= earlystopping:\n",
    "            print(f\"Stopping early --> val_loss has not decreased over {earlystopping} epochs\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaliSGKAmRsv"
   },
   "source": [
    "Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHoQ8SkmRyI"
   },
   "outputs": [],
   "source": [
    "# Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# comment just adds this to the file-name (could also be empty)\n",
    "writer = SummaryWriter(comment=f\"{model.__class__.__name__}\")\n",
    "\n",
    "# ... later, after validation is done:\n",
    "writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "writer.add_scalar('Loss/val', val_loss, epoch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oLSMwg84dHjf"
   ],
   "name": "Coding AI - Intro to PyTorch - Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

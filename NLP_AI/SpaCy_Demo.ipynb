{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SpaCy_Demo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuFH+ies/LtGqyS2r3b0c4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dN5yfKdgCPDV","colab_type":"text"},"source":["<img src=\"https://www.aiforpeople.org/wp-content/uploads/2020/01/cropped-AIforPeople-logo-full-2.png\" width=\"200\">\n","\n","## Natual Language Processing with Python using SpaCy\n","\n","In this quick tutorial we are going to look at some basic natural language algorithms that the [SpaCy](https://spacy.io/) package allows us to use. The API can be found [here](https://spacy.io/api) and promises *Industrial-Strength*\n","Natural Language Processing.\n","\n","This tutorial is run in a Google Colaboratory. Colab notebooks allow you to combine executable code and rich text in a single document, along with images, HTML, LaTeX and more. The entire code is run on a remote Google server. The usage is free, but limited: Google Colab gives you free RAM (13GB) and a GPU (up to 8GB) for up to 12hrs at a time. Using Colab, we can make sure that everyone is running the exact same code with the exact same system. Currently, the server has installed only some basic packages for Python. We can check the current python version by running the next cell:"]},{"cell_type":"code","metadata":{"id":"vlgpC3NXFsV8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595595886395,"user_tz":-120,"elapsed":4021,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"be76ec99-0563-425c-eab0-e34f8df0a06c"},"source":["!python --version"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Python 3.6.9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1szHaYtJHEkt","colab_type":"text"},"source":["We can see that we are running Python version 3.6.9 on the instance of the server. Now, we can check which of the NLP packages we'd like to use has already been installed. With the next line of code, we are asking `pip` the package installation tool to `list` the `version` of the packages which we find with **g**lobal search for a **r**egular **e**xpression and **p**rint out matches (`grep`). The regular expression we use is `nltk\\|spacy\\|gensim\\|corenlp\\|textblob\\|pattern\\|polyglot\\|scikit` in order to find the relevant NLP packages."]},{"cell_type":"code","metadata":{"id":"yfgD2l82GKUl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1595595889365,"user_tz":-120,"elapsed":6975,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"f39bb91b-8164-4f37-8671-9d3e1a151677"},"source":["!pip list --version | grep 'nltk\\|spacy\\|gensim\\|corenlp\\|textblob\\|pattern\\|polyglot\\|scikit'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["gensim                   3.6.0          \n","nltk                     3.2.5          \n","scikit-image             0.16.2         \n","scikit-learn             0.22.2.post1   \n","spacy                    2.2.4          \n","textblob                 0.15.3         \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JXB5iXanIWN5","colab_type":"text"},"source":["It seems that some of the packages have already been installed. Most importantly, we want to work with **SpaCy**. Now, we need to obtain the *English* (`en`) data for spacy with the following line of code. It will automaticall download the data we need."]},{"cell_type":"code","metadata":{"id":"opOdlTe0Sbho","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1595595894936,"user_tz":-120,"elapsed":12535,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"759a5350-7c11-4bbd-c7c9-ef3c36b45af2"},"source":["!python -m spacy download en_core_web_lg"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (49.1.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2FKWFVxAI8t-","colab_type":"text"},"source":["## Some NLP Basics with Spacy\n","Next, we will `import` the SpaCy package and start with some basics of text processing. Since we have downloaded the English `en` models to work with English texts, we can `load` the model. Then, we can put a sentence into the nlp instance and retrieve a new object from SpaCy. Here, we call that interpretation of the sentence `document`. This `document` is now comprised of several pieces of information (`tokens`) provided by the SpaCy model. If we look at every token in the `text` of the document, we can list all syntactical units of our original sentence, i.e. every word of the sentence: "]},{"cell_type":"code","metadata":{"id":"dyAdsqylSkQO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1595595896075,"user_tz":-120,"elapsed":13660,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"b1a161c9-de5d-4a09-d6f9-352059e32826"},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","sentence = \"This workshop is awesome!\"\n","document = nlp(sentence)\n","\n","for token in document:\n","    print('\"' + token.text + '\"')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\"This\"\n","\"workshop\"\n","\"is\"\n","\"awesome\"\n","\"!\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bCjZvKpR3LIW","colab_type":"text"},"source":["We can now investigate every token (word) within the sentence for more information that has been infered by the SpaCy `en` language model. Among a variety of properties, we can now look at Part-of-Speech (`POS`) tags, the syntactic dependency (`Dep`), whether the token is composed of alphabetical characters (`is alpha`) and much more:\n","- **Text**: The original word text.\n","- **Index**: Index of the word\n","- **Lemma**: The base form of the word.\n","- **POS**: The simple UPOS part-of-speech tag.\n","- **Tag**: The detailed part-of-speech tag.\n","- **Dep**: Syntactic dependency, i.e. the relation between tokens.\n","- **Shape**: The word shape – capitalization, punctuation, digits.\n","- **is alpha**: Is the token an alphabetical character?\n","- **is stop**: Is the token part of a stop list, i.e. the most common words of the language?"]},{"cell_type":"code","metadata":{"id":"OZl0GSe3SvKl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1595595896077,"user_tz":-120,"elapsed":13652,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"a4f32260-f9c0-403d-d046-ed121b0837c5"},"source":["# Token class exposes a lot of word-level attributes\n","\n","doc = nlp(u\"This class is awesome.\")\n","print(\"Text\\t\\tIndex\\t\\tLemma\\t\\tPOS\\t\\tTag\\t\\tDep\\t\\tShape\\t\\tis alpha\\tis stop\")\n","print(\"---------------------------------------------------------------------------------------------------------------------------------------\")\n","for token in doc:\n","    print(\"{0}\\t\\t{1}\\t\\t{2}\\t\\t{3}\\t\\t{4}\\t\\t{5}\\t\\t{6}\\t\\t{7}\\t\\t{8}\".format(\n","        token.text,\n","        token.idx,\n","        token.lemma_,\n","        token.pos_,\n","        token.tag_,\n","        token.dep_,\n","        token.shape_,\n","        token.is_alpha,\n","        token.is_stop\n","    ))\n"," "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Text\t\tIndex\t\tLemma\t\tPOS\t\tTag\t\tDep\t\tShape\t\tis alpha\tis stop\n","---------------------------------------------------------------------------------------------------------------------------------------\n","This\t\t0\t\tthis\t\tDET\t\tDT\t\tdet\t\tXxxx\t\tTrue\t\tTrue\n","class\t\t5\t\tclass\t\tNOUN\t\tNN\t\tnsubj\t\txxxx\t\tTrue\t\tFalse\n","is\t\t11\t\tbe\t\tAUX\t\tVBZ\t\tROOT\t\txx\t\tTrue\t\tTrue\n","awesome\t\t14\t\tawesome\t\tADJ\t\tJJ\t\tacomp\t\txxxx\t\tTrue\t\tFalse\n",".\t\t21\t\t.\t\tPUNCT\t\t.\t\tpunct\t\t.\t\tFalse\t\tFalse\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2gctGI9hIPIk","colab_type":"text"},"source":["A named entity is a “real-world object” that is assigned a name – for example, a person, a country, a product or a book title. Entites can also entail quantities, e.g. time, amount, percentage. **SpaCy** can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn’t always work perfectly and might need some tuning later, depending on your use case. This can be used to extract information about entities from a corpus and those entities can then be connected with further information. The next line will infer some entities and quantities from an example sentence:"]},{"cell_type":"code","metadata":{"id":"cott9Ku9TF3H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1595595896080,"user_tz":-120,"elapsed":13646,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"aae10286-e3cb-4394-fe50-10f93fdd41c4"},"source":["doc = nlp(u\"I just bought 2 pairs of shoes from Amazon at 12 p.m. because the sale with 30% off was about to expire.\")\n","for entity in doc.ents:\n","    print(entity.text, entity.label_)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2 CARDINAL\n","Amazon ORG\n","12 p.m. TIME\n","30% PERCENT\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R-luzbP2KZhV","colab_type":"text"},"source":["We can also **visualize** the information we've extracted and the quantities identified by the model. For this, we can use the in-built visualize `displacy` that we can simply import from the spacy package. As we want to render entities, we set the style to `ent` and since we are working in a jupyter notebook in this Google Colab, we set `jupyter` to `True`."]},{"cell_type":"code","metadata":{"id":"lNkpetOJTWXl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595595896081,"user_tz":-120,"elapsed":13637,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"46b7bca3-19d1-4630-f1af-c0c1ffa927f8"},"source":["from spacy import displacy\n","displacy.render(doc, style='ent', jupyter=True)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," pairs of shoes from \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Amazon\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," at \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    12 p.m.\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n","</mark>\n"," because the sale with \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    30%\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n","</mark>\n"," off was about to expire.</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"o1SQHgFdMUJI","colab_type":"text"},"source":["Not only can we visualize the recognized entities, but we can also visualize the dependency relations infered by the model. For this, we can take the example sentence *While hunting in Africa, I shot an elephant in my pajamas.* and create a new document (`doc`) from it. Now, we can simply change the render `style` to `dep` (dependency). Optionally, we can configure the `distance` of the words for the visualization-"]},{"cell_type":"code","metadata":{"id":"42hktk1FThW-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"status":"ok","timestamp":1595595896082,"user_tz":-120,"elapsed":13628,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"88bb082c-cb2a-4c58-9e53-b3280ea780e3"},"source":["doc = nlp(u'While hunting in Africa, I shot an elephant in my pajamas.')\n","displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1b794de590f845c39118dd45de3aed46-0\" class=\"displacy\" width=\"1040\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">While</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SCONJ</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">hunting</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">in</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">Africa,</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">shot</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">an</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">elephant</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">in</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">my</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">pajamas.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,137.0 125.0,137.0 125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,2.0 500.0,2.0 500.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-2\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M215.0,184.0 L223.0,172.0 207.0,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,137.0 305.0,137.0 305.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M305.0,184.0 L313.0,172.0 297.0,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-4\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-6\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M670.0,184.0 L678.0,172.0 662.0,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-7\" stroke-width=\"2px\" d=\"M520,182.0 C520,47.0 765.0,47.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M765.0,184.0 L773.0,172.0 757.0,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-1b794de590f845c39118dd45de3aed46-0-9\" stroke-width=\"2px\" d=\"M790,182.0 C790,92.0 940.0,92.0 940.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-1b794de590f845c39118dd45de3aed46-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M940.0,184.0 L948.0,172.0 932.0,172.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"om0M3s7EAi62","colab_type":"text"},"source":["## Word Similarities\n","An important aspect of Natural Language Processing is the investigation of similarities between texts. We can situate each word of our corpus in a conceptual space and this will allow us to compare the \"distance\" of words within this space. Such an approach makes use of so-called \"word embeddings\". We are going to have a look at a simple example before we will explain word embeddings in more detail in the next part of the lecture.\n","\n","In order to compare our words, we have to load one of the language models. The bigger the language model, the more fine-grained (the better) the similarity analysis."]},{"cell_type":"code","metadata":{"id":"HumuJDeU-MvH","colab_type":"code","colab":{}},"source":["nlp = spacy.load('en_core_web_lg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2taDpwfkP-MN","colab_type":"text"},"source":["\n","\n","spaCy is able to compare two objects, and make a prediction of how similar they are. Predicting similarity is useful for lots of reasons. For example, you can suggest a user content that’s similar to what they’re currently looking at.\n","\n","Each `doc` comes with a `.similarity()` method that lets you compare it with another object, and determine the similarity. Of course similarity is always subjective – whether “dog” and “cat” are similar really depends on how you’re looking at it. spaCy’s similarity model usually assumes a pretty general-purpose definition of similarity."]},{"cell_type":"code","metadata":{"id":"tZxQvHdHX6My","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1595599372019,"user_tz":-120,"elapsed":592,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"25e301dd-685d-4388-b9ee-229e297f1839"},"source":["# Computing Similiarity\n","\n","banana = nlp.vocab[u'banana']\n","dog = nlp.vocab[u'dog']\n","fruit = nlp.vocab[u'fruit']\n","animal = nlp.vocab[u'animal']\n","shiba = nlp.vocab[u'shiba']\n"," \n","print(\"Dog <=> Animal: \\t\", dog.similarity(animal))\n","print(\"Dog <=> Fruit: \\t\\t\",  dog.similarity(fruit))\n","print(\"Banana <=> Fruit: \\t\", banana.similarity(fruit))\n","print(\"Banana <=> Animal: \\t\",  banana.similarity(animal)) \n","print(\"Fruit <=> Animal: \\t\",  fruit.similarity(animal))\n","print(\"Dog <=> Banana: \\t\",  dog.similarity(banana))\n","print()\n","print(\"Dog <=> Shiba: \\t\\t\",  dog.similarity(shiba)) \n","print(\"Banana <=> Shiba: \\t\",  banana.similarity(shiba)) "],"execution_count":24,"outputs":[{"output_type":"stream","text":["Dog <=> Animal: \t 0.66185343\n","Dog <=> Fruit: \t\t 0.23552851\n","Banana <=> Fruit: \t 0.67148364\n","Banana <=> Animal: \t 0.24272855\n","Fruit <=> Animal: \t 0.33342767\n","Dog <=> Banana: \t 0.24327643\n","\n","Dog <=> Shiba: \t\t 0.3531367\n","Banana <=> Shiba: \t 0.09621696\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NAyUZYwmJ7r-","colab_type":"text"},"source":["![alt text](https://i.imgur.com/fUJjyhT.png)"]},{"cell_type":"markdown","metadata":{"id":"-VxuJOCBAo-W","colab_type":"text"},"source":["We can now see that the similarity values seem to be meaningful! The dog is more similar to animals than to a banana! And if that was too easy to be convincing, we can see that the Shiba dog is also very close to dog and far away from banana in the semantic space. How does these values come to be? \n","\n","For this we can have a closer look at the data attached to **dog** and **banana**. Let us print the vector of both items:"]},{"cell_type":"code","metadata":{"id":"H67wDBSg_MQ3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595600482568,"user_tz":-120,"elapsed":565,"user":{"displayName":"Philipp Wicke","photoUrl":"","userId":"03709409714906786353"}},"outputId":"d5a5ad3a-a270-47bf-b1bf-42d521d4d9bb"},"source":["tokens = nlp(\"dog banana\")\n","\n","for token in tokens:\n","    print(token.text)\n","    print(token.vector.shape)\n","    print(token.vector)\n","    print(\"\\n\")"],"execution_count":26,"outputs":[{"output_type":"stream","text":["dog\n","(300,)\n","[-4.0176e-01  3.7057e-01  2.1281e-02 -3.4125e-01  4.9538e-02  2.9440e-01\n"," -1.7376e-01 -2.7982e-01  6.7622e-02  2.1693e+00 -6.2691e-01  2.9106e-01\n"," -6.7270e-01  2.3319e-01 -3.4264e-01  1.8311e-01  5.0226e-01  1.0689e+00\n","  1.4698e-01 -4.5230e-01 -4.1827e-01 -1.5967e-01  2.6748e-01 -4.8867e-01\n","  3.6462e-01 -4.3403e-02 -2.4474e-01 -4.1752e-01  8.9088e-02 -2.5552e-01\n"," -5.5695e-01  1.2243e-01 -8.3526e-02  5.5095e-01  3.6410e-01  1.5361e-01\n","  5.5738e-01 -9.0702e-01 -4.9098e-02  3.8580e-01  3.8000e-01  1.4425e-01\n"," -2.7221e-01 -3.7016e-01 -1.2904e-01 -1.5085e-01 -3.8076e-01  4.9583e-02\n","  1.2755e-01 -8.2788e-02  1.4339e-01  3.2537e-01  2.7226e-01  4.3632e-01\n"," -3.1769e-01  7.9405e-01  2.6529e-01  1.0135e-01 -3.3279e-01  4.3117e-01\n","  1.6687e-01  1.0729e-01  8.9418e-02  2.8635e-01  4.0117e-01 -3.9222e-01\n","  4.5217e-01  1.3521e-01 -2.8878e-01 -2.2819e-02 -3.4975e-01 -2.2996e-01\n","  2.0224e-01 -2.1177e-01  2.7184e-01  9.1703e-02 -2.0610e-01 -6.5758e-01\n","  1.8949e-01 -2.6756e-01  9.2639e-02  4.3316e-01 -4.8868e-01 -3.8309e-01\n"," -2.1910e-01 -4.4183e-01  9.8044e-01  6.7423e-01  8.4003e-01 -1.8169e-01\n","  1.7385e-01  4.1848e-01  1.6098e-01 -1.0490e-01 -4.1965e-01 -3.5660e-01\n"," -1.6837e-01 -6.3458e-01  3.8422e-01 -3.5043e-01  1.7486e-01  5.3528e-01\n","  2.0143e-01  3.7877e-02  4.7105e-01 -4.4344e-01  1.6840e-01 -1.6685e-01\n"," -2.4022e-01 -1.0077e-01  3.0334e-01  4.2730e-01  3.3803e-01 -4.3481e-01\n","  1.1343e-01  6.1958e-02  6.1808e-02 -1.4007e-01  8.2018e-02 -3.9130e-02\n","  5.1442e-02  2.8725e-01  5.8025e-01 -5.7641e-01 -3.4652e-01  1.0132e-01\n","  1.4463e-01  1.1569e-02 -3.3701e-01 -1.7586e-01 -3.5724e-01 -2.1423e-01\n","  1.1429e-02  4.7645e-01 -3.7463e-02 -2.9488e-01 -1.7465e-01  3.0255e-01\n","  6.0317e-01 -6.6790e-02 -2.7050e+00 -7.0308e-01  4.0548e-01  6.2874e-01\n","  6.3080e-01 -5.4513e-01 -9.6191e-03  2.6533e-01  2.3391e-01 -5.1886e-02\n"," -6.5759e-03  1.8573e-02 -4.5693e-01 -7.0351e-02 -3.0621e-01 -1.4018e-02\n"," -2.0408e-01  3.7100e-01 -3.2354e-01 -8.4646e-01  2.7092e-01 -1.1961e-01\n"," -9.5576e-02 -6.0464e-01  4.2409e-02  2.4656e-01  3.8445e-02 -2.5467e-02\n"," -9.2908e-02 -2.1356e-01  3.6120e-01  1.9113e-02  6.2741e-02 -1.3083e-01\n"," -1.5146e-03  5.8238e-01 -1.8956e-01  7.8105e-01  1.0477e-02  1.0928e+00\n","  1.0140e-01 -3.6248e-01 -1.1962e-01 -3.4462e-01 -5.5704e-01  2.5797e-01\n","  3.3356e-01  3.3194e-01 -3.1298e-01 -7.5547e-01 -7.5290e-01 -9.3072e-02\n"," -1.1173e-01 -5.7251e-01  1.6639e-01  6.3579e-01  2.4006e-01 -2.9211e-01\n","  9.0182e-01  1.2425e-01 -5.7751e-01  4.7986e-02 -4.2748e-01  2.4446e-01\n","  4.7232e-02  3.5694e-01  4.4241e-01 -2.3055e-01  6.6037e-01 -7.3983e-03\n"," -3.7857e-01  2.2759e-01 -3.7138e-01  3.1055e-01 -7.2105e-02 -2.4490e-01\n"," -3.9761e-02  5.3650e-01 -4.1478e-01  1.6563e-01  3.3707e-01  1.0920e-01\n","  3.7219e-01 -5.5727e-01 -7.8060e-01  1.4251e-01 -3.5828e-01  4.1638e-01\n","  2.1446e-01  1.8410e-01 -4.7704e-01 -2.2005e-02 -2.3634e-01 -2.2840e-01\n","  3.4722e-01  2.3667e-01  7.4249e-02 -8.8416e-02  2.8618e-01 -4.6942e-01\n"," -4.3914e-01 -2.6474e-01 -3.0690e-01 -1.5260e-01 -8.4870e-02  2.8410e-01\n"," -1.8481e-01 -2.2122e-01 -1.1169e-01 -2.5241e-02  4.5968e-02  3.5343e-02\n","  2.2467e-01  5.1556e-01 -6.5137e-04  9.9559e-02 -1.4215e-01  2.0136e-01\n","  2.8334e-01 -2.8772e-01  3.7766e-02 -3.7608e-01 -1.1681e-01 -6.7020e-01\n"," -4.6265e-02  3.8784e-01 -3.2295e-02 -5.4291e-02 -4.5384e-01  1.9552e-01\n"," -2.9470e-01  8.5009e-01  1.0345e-01  9.7010e-02  1.1339e-01  3.9502e-01\n","  5.9043e-02  2.1978e-01  1.8845e-01 -1.5891e-01 -1.0301e-01  3.3164e-01\n","  6.1477e-02 -2.9848e-01  4.4510e-01  4.7329e-01  2.6312e-01 -1.8495e-01\n","  1.4652e-01 -3.1510e-02  2.2908e-02 -2.5929e-01 -3.0862e-01  1.7545e-03\n"," -1.8962e-01  5.4789e-01  3.1194e-01  2.4693e-01  2.9929e-01 -7.4861e-02]\n","\n","\n","banana\n","(300,)\n","[ 2.0228e-01 -7.6618e-02  3.7032e-01  3.2845e-02 -4.1957e-01  7.2069e-02\n"," -3.7476e-01  5.7460e-02 -1.2401e-02  5.2949e-01 -5.2380e-01 -1.9771e-01\n"," -3.4147e-01  5.3317e-01 -2.5331e-02  1.7380e-01  1.6772e-01  8.3984e-01\n","  5.5107e-02  1.0547e-01  3.7872e-01  2.4275e-01  1.4745e-02  5.5951e-01\n","  1.2521e-01 -6.7596e-01  3.5842e-01 -4.0028e-02  9.5949e-02 -5.0690e-01\n"," -8.5318e-02  1.7980e-01  3.3867e-01  1.3230e-01  3.1021e-01  2.1878e-01\n","  1.6853e-01  1.9874e-01 -5.7385e-01 -1.0649e-01  2.6669e-01  1.2838e-01\n"," -1.2803e-01 -1.3284e-01  1.2657e-01  8.6723e-01  9.6721e-02  4.8306e-01\n","  2.1271e-01 -5.4990e-02 -8.2425e-02  2.2408e-01  2.3975e-01 -6.2260e-02\n","  6.2194e-01 -5.9900e-01  4.3201e-01  2.8143e-01  3.3842e-02 -4.8815e-01\n"," -2.1359e-01  2.7401e-01  2.4095e-01  4.5950e-01 -1.8605e-01 -1.0497e+00\n"," -9.7305e-02 -1.8908e-01 -7.0929e-01  4.0195e-01 -1.8768e-01  5.1687e-01\n","  1.2520e-01  8.4150e-01  1.2097e-01  8.8239e-02 -2.9196e-02  1.2151e-03\n","  5.6825e-02 -2.7421e-01  2.5564e-01  6.9793e-02 -2.2258e-01 -3.6006e-01\n"," -2.2402e-01 -5.3699e-02  1.2022e+00  5.4535e-01 -5.7998e-01  1.0905e-01\n","  4.2167e-01  2.0662e-01  1.2936e-01 -4.1457e-02 -6.6777e-01  4.0467e-01\n"," -1.5218e-02 -2.7640e-01 -1.5611e-01 -7.9198e-02  4.0037e-02 -1.2944e-01\n"," -2.4090e-04 -2.6785e-01 -3.8115e-01 -9.7245e-01  3.1726e-01 -4.3951e-01\n","  4.1934e-01  1.8353e-01 -1.5260e-01 -1.0808e-01 -1.0358e+00  7.6217e-02\n","  1.6519e-01  2.6526e-04  1.6616e-01 -1.5281e-01  1.8123e-01  7.0274e-01\n","  5.7956e-03  5.1664e-02 -5.9745e-02 -2.7551e-01 -3.9049e-01  6.1132e-02\n","  5.5430e-01 -8.7997e-02 -4.1681e-01  3.2826e-01 -5.2549e-01 -4.4288e-01\n","  8.2183e-03  2.4486e-01 -2.2982e-01 -3.4981e-01  2.6894e-01  3.9166e-01\n"," -4.1904e-01  1.6191e-01 -2.6263e+00  6.4134e-01  3.9743e-01 -1.2868e-01\n"," -3.1946e-01 -2.5633e-01 -1.2220e-01  3.2275e-01 -7.9933e-02 -1.5348e-01\n","  3.1505e-01  3.0591e-01  2.6012e-01  1.8553e-01 -2.4043e-01  4.2886e-02\n","  4.0622e-01 -2.4256e-01  6.3870e-01  6.9983e-01 -1.4043e-01  2.5209e-01\n","  4.8984e-01 -6.1067e-02 -3.6766e-01 -5.5089e-01 -3.8265e-01 -2.0843e-01\n","  2.2832e-01  5.1218e-01  2.7868e-01  4.7652e-01  4.7951e-02 -3.4008e-01\n"," -3.2873e-01 -4.1967e-01 -7.5499e-02 -3.8954e-01 -2.9622e-02 -3.4070e-01\n","  2.2170e-01 -6.2856e-02 -5.1903e-01 -3.7774e-01 -4.3477e-03 -5.8301e-01\n"," -8.7546e-02 -2.3929e-01 -2.4711e-01 -2.5887e-01 -2.9894e-01  1.3715e-01\n","  2.9892e-02  3.6544e-02 -4.9665e-01 -1.8160e-01  5.2939e-01  2.1992e-01\n"," -4.4514e-01  3.7798e-01 -5.7062e-01 -4.6946e-02  8.1806e-02  1.9279e-02\n","  3.3246e-01 -1.4620e-01  1.7156e-01  3.9981e-01  3.6217e-01  1.2816e-01\n","  3.1644e-01  3.7569e-01 -7.4690e-02 -4.8480e-02 -3.1401e-01 -1.9286e-01\n"," -3.1294e-01 -1.7553e-02 -1.7514e-01 -2.7587e-02 -1.0000e+00  1.8387e-01\n","  8.1434e-01 -1.8913e-01  5.0999e-01 -9.1960e-03 -1.9295e-03  2.8189e-01\n","  2.7247e-02  4.3409e-01 -5.4967e-01 -9.7426e-02 -2.4540e-01 -1.7203e-01\n"," -8.8650e-02 -3.0298e-01 -1.3591e-01 -2.7765e-01  3.1286e-03  2.0556e-01\n"," -1.5772e-01 -5.2308e-01 -6.4701e-01 -3.7014e-01  6.9393e-02  1.1401e-01\n","  2.7594e-01 -1.3875e-01 -2.7268e-01  6.6891e-01 -5.6454e-02  2.4017e-01\n"," -2.6730e-01  2.9860e-01  1.0083e-01  5.5592e-01  3.2849e-01  7.6858e-02\n","  1.5528e-01  2.5636e-01 -1.0772e-01 -1.2359e-01  1.1827e-01 -9.9029e-02\n"," -3.4328e-01  1.1502e-01 -3.7808e-01 -3.9012e-02 -3.4593e-01 -1.9404e-01\n"," -3.3580e-01 -6.2334e-02  2.8919e-01  2.8032e-01 -5.3741e-01  6.2794e-01\n","  5.6955e-02  6.2147e-01 -2.5282e-01  4.1670e-01 -1.0108e-02 -2.5434e-01\n","  4.0003e-01  4.2432e-01  2.2672e-01  1.7553e-01  2.3049e-01  2.8323e-01\n","  1.3882e-01  3.1218e-03  1.7057e-01  3.6685e-01  2.5247e-03 -6.4009e-01\n"," -2.9765e-01  7.8943e-01  3.3168e-01 -1.1966e+00 -4.7156e-02  5.3175e-01]\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iSp59Y1xOgWt","colab_type":"text"},"source":["![alt text](https://thumbs.gfycat.com/QuickSevereCat-small.gif)"]}]}